{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "import copy\n",
    "\n",
    "from numpy.linalg import pinv\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.optimize import fmin_bfgs\n",
    "\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Linear:\n",
    "    def val(x):\n",
    "        return x\n",
    "    def dev(x):\n",
    "        return 1\n",
    "class TANH:\n",
    "    def val(x):\n",
    "        return np.tanh(x)\n",
    "    def dev(x):\n",
    "        return 1 - np.tanh(x)*np.tanh(x)\n",
    "class Sigmoid:\n",
    "    def val(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def dev(x):\n",
    "        return (1 / (1 + np.exp(-x))) * (1-1 / (1 + np.exp(-x)))\n",
    "class Relu:\n",
    "    def val(x):\n",
    "        return np.maximum(x,0)\n",
    "    def dev(x):\n",
    "        return (x>0).astype(int)\n",
    "class ArcTan:\n",
    "    def val(x):\n",
    "        return np.arctan(x)\n",
    "    def dev(x):\n",
    "        return 1/(x*x+1)\n",
    "class SiLU:\n",
    "    def val(x):\n",
    "        return x / (1 + np.exp(-x))\n",
    "    def dev(x):\n",
    "        return x / (1 + np.exp(-x)) + (1-x / (1 + np.exp(-x))) / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "def no_decay(eta,t,epoch):\n",
    "    return eta\n",
    "def exp_decay(eta,t,epoch):\n",
    "    eta = 0.001\n",
    "    k = 0.001\n",
    "    lrate = eta * np.exp(-k*t)\n",
    "    return lrate\n",
    "def inverse_decay(eta,t,epoch):\n",
    "    eta = 0.001\n",
    "    lrate = eta /(1+t/epoch)\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, C=0.0, epochs=500, eta=0.001, random_state=None, \n",
    "                 cost_function='quadratic', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='None',\n",
    "                 learning_rate = no_decay,\n",
    "                 early_stopping=False):\n",
    "        np.random.seed(random_state)\n",
    "        self.C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.cost_function = cost_function\n",
    "        self.metric = metric\n",
    "        self.verbose = verbose\n",
    "        self.regular = regular\n",
    "        self.early_stopping = early_stopping\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.dims = []\n",
    "        self.acts = []\n",
    "        \n",
    "        self.matrice = []\n",
    "        self.bias = []\n",
    "        self.vects = [] #before the activation function\n",
    "        self.neurons = [] #after the activation function\n",
    "        self.dropout = [] #to be implemented later\n",
    "        self.Y = []\n",
    "        \n",
    "        self.loss = []\n",
    "        \n",
    "    def add(self,arg,argv):\n",
    "        '''\n",
    "        add('Dense',12)\n",
    "        add('Dense',15)\n",
    "        add('Activation',Sigmoid)\n",
    "        add('Activation',Relu)\n",
    "        add('Dropout',0.5)\n",
    "        '''\n",
    "        if arg == 'Dense':\n",
    "            if len(self.dropout) < len(self.dims):\n",
    "                self.dropout.append(0)\n",
    "            if len(self.dims) == 0:\n",
    "                self.dims.append([0,argv])\n",
    "            else:\n",
    "                self.dims.append([self.dims[-1][-1],argv])\n",
    "        if arg == 'Activation':\n",
    "            self.acts.append(argv)\n",
    "        if arg == 'Dropout':\n",
    "            self.dropout.append(argv)\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_params(self,X,Y):\n",
    "        for row,col in self.dims:\n",
    "            W_num_elems = row*col\n",
    "            W = np.random.uniform(-1.0, 1.0, size=W_num_elems)\n",
    "            W = W.reshape(col, row) # reshape to be W\n",
    "            self.matrice.append(W)\n",
    "            \n",
    "            b = np.random.uniform(-1.0, 1.0, size=col)\n",
    "            b = b.reshape(col, 1)\n",
    "            self.bias.append(b) #adding bias vector\n",
    "        \n",
    "        self.neurons.append(X.T)\n",
    "        self.Y = self._encode_labels(Y)\n",
    "        return\n",
    "    \n",
    "    def activate(self,vec,act):\n",
    "        return act.val(vec)\n",
    "    \n",
    "    def activate_dev(self,vec,act):\n",
    "        return act.dev(vec)\n",
    "    \n",
    "    def _feedforward(self):\n",
    "        '''\n",
    "        clear the previous feedforward result\n",
    "        '''\n",
    "        self.neurons = self.neurons[:1]\n",
    "        self.vects = []\n",
    "        for W,b,act in zip(self.matrice,self.bias,self.acts):\n",
    "            self.vects.append(W @ self.neurons[-1] + b)\n",
    "            self.neurons.append(self.activate(self.vects[-1],act))\n",
    "            \n",
    "        if self.cost_function == 'quadratic':\n",
    "            self.loss.append(((self.neurons[-1]-self.Y)*(self.neurons[-1]-self.Y)).sum()/len(self.Y))\n",
    "        elif self.cost_function == 'cross_entropy':\n",
    "            m = self.Y.shape[1]\n",
    "            cost = -(1.0/m) * np.sum(self.Y*np.log(self.neurons[-1]) + (1-self.Y)*np.log(1-self.neurons[-1]))\n",
    "            self.loss.append(cost)\n",
    "        return\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        neuron = X_test.T\n",
    "        for W,b,act in zip(self.matrice,self.bias,self.acts):\n",
    "            vec = W @ neuron + b\n",
    "            neuron = self.activate(vec,act)\n",
    "        y_pred = np.argmax(neuron, axis=0)\n",
    "        return y_pred\n",
    "    \n",
    "    def set_init_dev_prefix(self):\n",
    "        if self.cost_function == 'quadratic':\n",
    "            return -2 * (self.Y - self.neurons[-1])\n",
    "        if self.cost_function == 'cross_entropy':\n",
    "            return -(self.Y/self.neurons[-1] +(self.Y-1)/(self.neurons[-1]-1))\n",
    "\n",
    "    def _update_params(self):\n",
    "        cur_dev_prefix = self.set_init_dev_prefix()\n",
    "        grads = []\n",
    "        bias_grads = []\n",
    "        for N,N1,V,act,W in zip(self.neurons[1:][::-1],self.neurons[:-1][::-1],self.vects[::-1],self.acts[::-1],self.matrice[::-1]):\n",
    "            cur_dev_prefix *= self.activate_dev(V,act)\n",
    "            grads.append(cur_dev_prefix @ N1.T)\n",
    "            bias_grads.append(cur_dev_prefix @ np.full((cur_dev_prefix.shape[1], 1), 1))\n",
    "            cur_dev_prefix = W.T @ cur_dev_prefix                \n",
    "        grads.reverse()\n",
    "        bias_grads.reverse()\n",
    "        \n",
    "        if self.regular != 'None':\n",
    "            for W,b,grad,bias_grad in zip(self.matrice,self.bias,grads,bias_grads):\n",
    "                if 'L2' in self.regular:\n",
    "                    grad += 2*self.C * W\n",
    "                    bias_grad += 2*self.C * b\n",
    "                if 'L1' in self.regular:\n",
    "                    grad += ((W>0).astype(int)-0.5)*(2*self.C)\n",
    "                    bias_grad += self.C *((b>0).astype(int)-0.5)*(2*self.C)\n",
    "                    \n",
    "        for W,grad,b,bias_grad in zip(self.matrice,grads,self.bias,bias_grads):\n",
    "            W -= self.eta * grad\n",
    "            b -= self.eta * bias_grad\n",
    "        return\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        self.dims[0][0] = X.shape[1]\n",
    "        if len(np.unique(Y)) != self.dims[-1][-1]:\n",
    "            print('Error: output dimension is wrong!')\n",
    "            return False\n",
    "        self._initialize_params(X,Y)\n",
    "        #print(self.dims)\n",
    "        #print([x.shape for x in self.matrice])\n",
    "        #print([x.shape for x in self.bias])\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            self.eta = self.learning_rate(self.eta,i,self.epochs)\n",
    "            self._feedforward()\n",
    "            self._update_params()\n",
    "            \n",
    "            if self.verbose and not i % max(1,int(self.epochs/10)):\n",
    "                if self.metric == 'accuracy':\n",
    "                    accu = accuracy_score(np.argmax(self.neurons[-1], axis=0),Y)\n",
    "                print('{} percent finished, current accuracy is {}.'.format(100*i//self.epochs,accu))\n",
    "        plt.figure()\n",
    "        plt.plot([i for i in range(self.epochs)],self.loss)\n",
    "        print('Training is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percent finished, current accuracy is 0.3333333333333333.\n",
      "10 percent finished, current accuracy is 0.82.\n",
      "20 percent finished, current accuracy is 0.92.\n",
      "30 percent finished, current accuracy is 0.9733333333333334.\n",
      "40 percent finished, current accuracy is 0.9666666666666667.\n",
      "50 percent finished, current accuracy is 0.9666666666666667.\n",
      "60 percent finished, current accuracy is 0.9666666666666667.\n",
      "70 percent finished, current accuracy is 0.96.\n",
      "80 percent finished, current accuracy is 0.9666666666666667.\n",
      "90 percent finished, current accuracy is 0.9666666666666667.\n",
      "Training is done!\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential(C=0.1, epochs=1000, eta=0.001, random_state=None, \n",
    "                 cost_function='quadratic', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='L1',\n",
    "                 learning_rate=inverse_decay)\n",
    "model.add('Dense',3)\n",
    "model.add('Activation',Relu)\n",
    "model.add('Dense',20)\n",
    "model.add('Activation',TANH)\n",
    "model.add('Dense',28)\n",
    "model.add('Activation',Sigmoid)\n",
    "model.add('Dense',3)\n",
    "model.add('Activation',Sigmoid)\n",
    "\n",
    "ds = load_iris()\n",
    "X = ds.data\n",
    "X_test = StandardScaler().fit(X).transform(X)\n",
    "X = StandardScaler().fit(X).transform(X)\n",
    "Y = ds.target # note problem is NOT binary anymore, there are three classes!\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "print(model.predict(X))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
