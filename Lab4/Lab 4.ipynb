{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "import copy\n",
    "\n",
    "from numpy.linalg import pinv\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.optimize import fmin_bfgs\n",
    "\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def val(x):\n",
    "        return x\n",
    "    def dev(x):\n",
    "        return 1\n",
    "class TANH:\n",
    "    def val(x):\n",
    "        return np.tanh(x)\n",
    "    def dev(x):\n",
    "        return 1 - np.tanh(x)*np.tanh(x)\n",
    "class Sigmoid:\n",
    "    def val(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def dev(x):\n",
    "        return (1 / (1 + np.exp(-x))) * (1-1 / (1 + np.exp(-x)))\n",
    "class Relu:\n",
    "    def val(x):\n",
    "        return np.maximum(x.copy(),0)\n",
    "    def dev(x):\n",
    "        return (x>0).astype(int)\n",
    "class ArcTan:\n",
    "    def val(x):\n",
    "        return np.arctan(x)\n",
    "    def dev(x):\n",
    "        return 1/(x*x+1)\n",
    "class SiLU:\n",
    "    def val(x):\n",
    "        return x / (1 + np.exp(-x))\n",
    "    def dev(x):\n",
    "        return x / (1 + np.exp(-x)) + (1-x / (1 + np.exp(-x))) / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def no_decay(eta,t,epoch):\n",
    "    return eta\n",
    "def exp_decay(eta,t,epoch):\n",
    "    k = 0.001\n",
    "    lrate = eta * np.exp(-k*t)\n",
    "    return lrate\n",
    "def inverse_decay(eta,t,epoch):\n",
    "    lrate = eta /(1+t/epoch)\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can write the cost function in the following fashion.\n",
    "\\begin{equation*}\n",
    "cost\\_ function = f_i(\\phi_{i} (M_i \\phi_{i-1}(M_{i-1} N_{i-2}+b_{i-1}) + b_i))\n",
    "\\end{equation*}\n",
    "in which, $f_i$ represents all the afterward layers and the cost function definition, $b_i$ is the bias term for the $i$-th layer, and $N_i$ is the neuron value of the $i$-th layer, $V_i$ is the value before apply the activation function($V_i = M_{i} N_{i-1}+b_{i}$). \n",
    "\n",
    "We find that:\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial (cost\\_ function)}{\\partial M_i} = f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i)* N_{i-1}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial (cost\\_ function)}{\\partial b_i} = f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i)\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial (cost\\_ function)}{\\partial M_{i-1}} = f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i)* M_{i}*\\phi_{i-1}^{'}(V_{i-1})*N_{i-2}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial (cost\\_ function)}{\\partial b_{i-1}} = f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i)* M_{i}*\\phi_{i-1}^{'}(V_{i-1})\n",
    "\\end{equation*}\n",
    "In principle we can also write the third equation as,\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial (cost\\_ function)}{\\partial M_{i-1}} = f_{i-1} ^{'}(N_{i-1})*\\phi_{i-1}^{'}(V_{i-1})*N_{i-2}\n",
    "\\end{equation*}\n",
    "which gives us that\n",
    "\\begin{equation*}\n",
    " f_{i-1} ^{'}(N_{i-1})= f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i)* M_{i}\n",
    "\\end{equation*}\n",
    "We can refer $f_i ^{'}(N_{i})$ as the derivative_prefix, and as long as we can keep track of the derivative_prefix in different layers, we can calculate the partial derivative of each layer efficiently.\n",
    "\n",
    "Note that, in the formulas above, we only show the ingredients of every equation for the purpose of simplicity, in the actual formula, we need to move the matrice around and use different multiplications carefully.\n",
    "\n",
    "The actual iterations are as follow:\n",
    "\\begin{equation*} \n",
    " f_{i-1} ^{'}(N_{i-1})=  M_{i}^T@f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i)\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial (cost\\_ function)}{\\partial M_i} = f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i)@ N_{i-1}^T\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial (cost\\_ function)}{\\partial b_i} = f_i ^{'}(N_{i}) * \\phi_{i}^{'}(V_i) @ I\n",
    "\\end{equation*}\n",
    "In the last formula, $I$ is a matrix with value 1.\n",
    "\n",
    "\n",
    "We start with the last layer, and the initial derivative_prefix is the derivative of the cost_fuction (either mean square error or cross entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, C=0.0, epochs=500, eta=0.001, random_state=None, \n",
    "                 cost_function='quadratic', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='None',\n",
    "                 learning_rate = no_decay,\n",
    "                 early_stopping=False):\n",
    "        np.random.seed(random_state)\n",
    "        self.C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.cost_function = cost_function\n",
    "        self.metric = metric\n",
    "        self.verbose = verbose\n",
    "        self.regular = regular\n",
    "        self.early_stopping = early_stopping\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.dims = []\n",
    "        self.acts = []\n",
    "        \n",
    "        self.matrice = []\n",
    "        self.bias = []\n",
    "        self.vects = [] #before the activation function\n",
    "        self.neurons = [] #after the activation function\n",
    "        self.dropout = [] #to be implemented later\n",
    "        self.Y = []\n",
    "        \n",
    "        self.loss = []\n",
    "        \n",
    "    def add(self,arg,argv):\n",
    "        '''\n",
    "        add('Dense',12)\n",
    "        add('Dense',15)\n",
    "        add('Activation',Sigmoid)\n",
    "        add('Activation',Relu)\n",
    "        add('Dropout',0.5)\n",
    "        '''\n",
    "        if arg == 'Dense':\n",
    "            if len(self.dropout) < len(self.dims):\n",
    "                self.dropout.append(0)\n",
    "            if len(self.dims) == 0:\n",
    "                self.dims.append([0,argv])\n",
    "            else:\n",
    "                self.dims.append([self.dims[-1][-1],argv])\n",
    "        if arg == 'Activation':\n",
    "            self.acts.append(argv)\n",
    "        if arg == 'Dropout':\n",
    "            self.dropout.append(argv)\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_params(self,X,Y):\n",
    "        for row,col in self.dims:\n",
    "            W_num_elems = row*col\n",
    "            W = np.random.uniform(-1.0, 1.0, size=W_num_elems)\n",
    "            W = W.reshape(col, row) # reshape to be W\n",
    "            self.matrice.append(W)\n",
    "            \n",
    "            b = np.random.uniform(-1.0, 1.0, size=col)\n",
    "            b = b.reshape(col, 1)\n",
    "            self.bias.append(b) #adding bias vector\n",
    "        \n",
    "        self.neurons.append(X.T)\n",
    "        self.Y = self._encode_labels(Y)\n",
    "        return\n",
    "    \n",
    "    def activate(self,vec,act):\n",
    "        return act.val(vec)\n",
    "    \n",
    "    def activate_dev(self,vec,act):\n",
    "        return act.dev(vec)\n",
    "    \n",
    "    def _feedforward(self):\n",
    "        '''\n",
    "        clear the previous feedforward result\n",
    "        '''\n",
    "        self.neurons = self.neurons[:1]\n",
    "        self.vects = []\n",
    "        for W,b,act in zip(self.matrice,self.bias,self.acts):\n",
    "            self.vects.append(W @ self.neurons[-1] + b)\n",
    "            self.neurons.append(self.activate(self.vects[-1],act))\n",
    "        m = self.Y.shape[1]\n",
    "        if self.cost_function == 'quadratic':\n",
    "            self.loss.append(((self.neurons[-1]-self.Y)*(self.neurons[-1]-self.Y)).sum()/m)\n",
    "        elif self.cost_function == 'cross_entropy':\n",
    "            cost = -(1.0/m) * np.sum(self.Y*np.log(self.neurons[-1]) + (1-self.Y)*np.log(1-self.neurons[-1]))\n",
    "            self.loss.append(cost)\n",
    "        return\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        neuron = X_test.T\n",
    "        for W,b,act in zip(self.matrice,self.bias,self.acts):\n",
    "            vec = W @ neuron + b\n",
    "            neuron = self.activate(vec,act)\n",
    "        y_pred = np.argmax(neuron, axis=0)\n",
    "        return y_pred\n",
    "\n",
    "    def set_init_dev_prefix(self):\n",
    "        if self.cost_function == 'quadratic':\n",
    "            return -2 * (self.Y - self.neurons[-1])\n",
    "        if self.cost_function == 'cross_entropy':\n",
    "            return -(self.Y-self.neurons[-1])\n",
    "\n",
    "    def _update_params(self):\n",
    "        cur_dev_prefix = self.set_init_dev_prefix()\n",
    "        grads = []\n",
    "        bias_grads = []\n",
    "        for N,N1,V,act,W in zip(self.neurons[1:][::-1],self.neurons[:-1][::-1],self.vects[::-1],self.acts[::-1],self.matrice[::-1]):\n",
    "            cur_dev_prefix *= self.activate_dev(V,act)\n",
    "            grads.append(cur_dev_prefix @ N1.T)\n",
    "            bias_grads.append(cur_dev_prefix @ np.full((cur_dev_prefix.shape[1], 1), 1))\n",
    "            cur_dev_prefix = W.T @ cur_dev_prefix\n",
    "        grads.reverse()\n",
    "        bias_grads.reverse()\n",
    "        \n",
    "        if self.regular != 'None':\n",
    "            for W,b,grad,bias_grad in zip(self.matrice,self.bias,grads,bias_grads):\n",
    "                if 'L2' in self.regular:\n",
    "                    grad += 2*self.C * W\n",
    "                    bias_grad += 2*self.C * b\n",
    "                if 'L1' in self.regular:\n",
    "                    grad += ((W>0).astype(int)-0.5)*(2*self.C)\n",
    "                    bias_grad += self.C *((b>0).astype(int)-0.5)*(2*self.C)\n",
    "                    \n",
    "        for W,grad,b,bias_grad in zip(self.matrice,grads,self.bias,bias_grads):\n",
    "            W -= self.eta * grad\n",
    "            b -= self.eta * bias_grad\n",
    "        return\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        self.dims[0][0] = X.shape[1]\n",
    "        if len(np.unique(Y)) != self.dims[-1][-1]:\n",
    "            print('Error: output dimension is wrong!')\n",
    "            return False\n",
    "        self._initialize_params(X,Y)\n",
    "        eta_0 = self.eta\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            self.eta = self.learning_rate(eta_0,i,self.epochs)\n",
    "            self._feedforward()\n",
    "            self._update_params()\n",
    "\n",
    "            if self.verbose and not i % max(1,int(self.epochs/10)):\n",
    "                if self.metric == 'accuracy':\n",
    "                    accu = accuracy_score(np.argmax(self.neurons[-1], axis=0),Y)\n",
    "                if self.metric == 'customized':\n",
    "                    accu = cost_metric()\n",
    "                print('{} percent finished, current accuracy is {:.3f}.'.format(100*i//self.epochs,accu))\n",
    "        if self.verbose:\n",
    "            plt.figure()\n",
    "            plt.plot([i for i in range(self.epochs-1)],self.loss[1:])\n",
    "            plt.xlabel('Epoch number')\n",
    "            plt.ylabel('Loss')\n",
    "        print('Training is done!')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percent finished, current accuracy is 0.132.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-777f8850149d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-23f83ee43194>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-23f83ee43194>\u001b[0m in \u001b[0;36m_feedforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_df = pd.read_csv('data/processed_data.csv')\n",
    "\n",
    "Y = full_df['readmitted'].replace({'NO':0,'<30':1,'>30':2}).values\n",
    "data_cols = list(full_df)\n",
    "data_cols.remove('readmitted')\n",
    "X = full_df[data_cols].values\n",
    "\n",
    "model = Sequential(C=0.001, epochs=2000, eta=0.00001, random_state=42, \n",
    "                 cost_function='cross_entropy', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='L1',\n",
    "                 learning_rate=no_decay)\n",
    "\n",
    "model.add('Dense',20)\n",
    "model.add('Activation',Relu)\n",
    "model.add('Dense',3)\n",
    "model.add('Activation',Sigmoid)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "print(model.predict(X))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator(param):\n",
    "    model = Sequential(C=0, epochs=2000, eta=0.00001, random_state=42, \n",
    "                 cost_function=param['cost_function'], \n",
    "                 metric='accuracy',\n",
    "                 verbose=0,\n",
    "                 regular='None',\n",
    "                 learning_rate=no_decay)\n",
    "    for neu_nbr, act in zip(param['Layers'],param['Activations']):\n",
    "        model.add('Dense',neu_nbr)\n",
    "        model.add('Activation',act)\n",
    "    model.fit(X,Y)\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y_pred,Y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "param_test = []\n",
    "activation_list = [Linear,TANH,Sigmoid,Relu,ArcTan,SiLU]*5\n",
    "for cost_function in ['cross_entropy','quadratic']:\n",
    "    for layer_nbr in range(2,4,1):\n",
    "        for k in range(4):\n",
    "            #for same objective function and nbr of layers, create 4 sets of parameters\n",
    "            neuron_list = [random.randint(5,40) for i in range(layer_nbr-1)] + [3]\n",
    "            #neuron number of hidden layers vary from 5 to 40\n",
    "            random.shuffle(activation_list)\n",
    "            act_list = activation_list[:layer_nbr-1] + [Sigmoid]\n",
    "            #activation function of hidden layers are randomly selected\n",
    "            tmp_param = {'cost_function':cost_function,'Layers':neuron_list,'Activations':act_list}\n",
    "            param_test.append(tmp_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n",
      "0.7733333333333333\n",
      "Training is done!\n",
      "0.46\n",
      "Training is done!\n",
      "0.7466666666666667\n",
      "Training is done!\n",
      "0.14\n",
      "Training is done!\n",
      "0.6666666666666666\n",
      "Training is done!\n",
      "0.4666666666666667\n",
      "Training is done!\n",
      "0.7733333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ecbf897d0766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-6d9ff687109c>\u001b[0m in \u001b[0;36mestimator\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dense'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneu_nbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Activation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-23f83ee43194>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-23f83ee43194>\u001b[0m in \u001b[0;36m_feedforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param in param_test:\n",
    "    print(estimator(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "Training is done!\n",
      "[0.7733333333333333, 0.46, 0.7466666666666667, 0.14, 0.6666666666666666, 0.4666666666666667, 0.7733333333333333, 0.8066666666666666, 0.4866666666666667, 0.8666666666666667, 0.18, 0.8, 0.7266666666666667, 0.94, 0.3333333333333333, 0.5066666666666667]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "pool = mp.Pool(processes=2)\n",
    "res = pool.map(estimator,param_test)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percent finished, current accuracy is 0.333.\n",
      "10 percent finished, current accuracy is 0.780.\n",
      "20 percent finished, current accuracy is 0.853.\n",
      "30 percent finished, current accuracy is 0.927.\n",
      "40 percent finished, current accuracy is 0.953.\n",
      "50 percent finished, current accuracy is 0.973.\n",
      "60 percent finished, current accuracy is 0.973.\n",
      "70 percent finished, current accuracy is 0.973.\n",
      "80 percent finished, current accuracy is 0.973.\n",
      "90 percent finished, current accuracy is 0.973.\n",
      "Training is done!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential(C=0.1, epochs=10000, eta=0.001, random_state=42, \n",
    "                 cost_function='cross_entropy', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='L1',\n",
    "                 learning_rate=inverse_decay)\n",
    "model.add('Dense',3)\n",
    "model.add('Activation',Sigmoid)\n",
    "model.add('Dense',20)\n",
    "model.add('Activation',Sigmoid)\n",
    "model.add('Dense',28)\n",
    "model.add('Activation',Sigmoid)\n",
    "model.add('Dense',3)\n",
    "model.add('Activation',Sigmoid)\n",
    "\n",
    "ds = load_iris()\n",
    "X = ds.data\n",
    "X_test = StandardScaler().fit(X).transform(X)\n",
    "X = StandardScaler().fit(X).transform(X)\n",
    "Y = ds.target # note problem is NOT binary anymore, there are three classes!\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "#print(model.predict(X))\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "ds = load_digits()\n",
    "X = ds.data/16.0-0.5\n",
    "Y = ds.target\n",
    "\n",
    "model = Sequential(C=0.1, epochs=1000, eta=0.001, random_state=None, \n",
    "                 cost_function='cross_entropy', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='L1',\n",
    "                 learning_rate=no_decay)\n",
    "model.add('Dense',60)\n",
    "model.add('Activation',Sigmoid)\n",
    "model.add('Dense',10)\n",
    "model.add('Activation',Sigmoid)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
