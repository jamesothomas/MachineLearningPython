{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "import copy\n",
    "\n",
    "from numpy.linalg import pinv\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.optimize import fmin_bfgs\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# split the data and the target\n",
    "train, test = train_test_split(df, test_size=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "ds = load_iris()\n",
    "X = ds.data\n",
    "\n",
    "X = StandardScaler().fit(X).transform(X)\n",
    "Y = ds.target # note problem is NOT binary anymore, there are three classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    '''\n",
    "    minibatch use stratified split\n",
    "    '''\n",
    "    def __init__(self, C=0.0, epochs=500, eta=0.001, random_state=None, \n",
    "                 cost_function='quadratic', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='None',\n",
    "                 #learning_rate = learning_rate,\n",
    "                 early_termination=False):\n",
    "        np.random.seed(random_state)\n",
    "        self.C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.cost_function = cost_function\n",
    "        self.metric = metric\n",
    "        self.verbose = verbose\n",
    "        self.regular = regular\n",
    "        self.early_termination = early_termination\n",
    "        #self.learning_rate = learning_rate\n",
    "        \n",
    "        self.dims = []\n",
    "        self.acts = []\n",
    "        \n",
    "        self.matrice = []\n",
    "        self.vects = [] #before the activation function\n",
    "        self.neurons = [] #after the activation function\n",
    "        self.dropout = []\n",
    "        \n",
    "    def add(self,arg,argv):\n",
    "        '''\n",
    "        add('Dense',12)\n",
    "        add('Dense',15)\n",
    "        add('Activation',Sigmoid)\n",
    "        add('Activation',Relu)\n",
    "        add('Dropout',0.5)\n",
    "        '''\n",
    "        if arg == 'Dense':\n",
    "            if len(self.dropout) < len(self.dims):\n",
    "                self.dropout.append(0)\n",
    "            if len(self.dims) == 0:\n",
    "                self.dims.append([0,argv])\n",
    "            else:\n",
    "                self.dims.append([self.dims[-1][-1],argv])\n",
    "        if arg == 'Activation':\n",
    "            self.acts.append(argv)\n",
    "        if arg == 'Dropout':\n",
    "            self.dropout.append(argv)\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "\n",
    "    def _initialize_params(self,X):\n",
    "        for row,col in self.dims:\n",
    "            W_num_elems = (row + 1)*col\n",
    "            W = np.random.uniform(-1.0, 1.0, size=W_num_elems)\n",
    "            W = W.reshape(col, row + 1) # reshape to be W\n",
    "            self.matrice.append(W)\n",
    "        self.neurons.append(X)\n",
    "        return\n",
    "    \n",
    "    def activate(self,vec,act):\n",
    "        return act.val(vec)\n",
    "    \n",
    "    def activate_dev(vec,neuron,act):\n",
    "        if act == sigmoid:\n",
    "            return neuron * (1-neuron)\n",
    "        else:\n",
    "            return act.dev(vec)\n",
    "    \n",
    "    def _feedforward(self):\n",
    "        for W,act in zip(self.matrice,self.acts):\n",
    "            self.vects.append(W @ self._add_bias_unit(self.neurons[-1].T, how='row'))\n",
    "            self.neurons.append(self.activate(self.vects[-1],act))\n",
    "        return\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        if X_test == self.neurons[0]:\n",
    "            y_pred = np.argmax(self.neurons[-1], axis=0)\n",
    "        else:\n",
    "            for W,act in zip(self.matrice,self.acts):\n",
    "                neuron = X_test\n",
    "                vec = W @ self._add_bias_unit(neuron.T, how='row')\n",
    "                neuron = self.activate(vec,act)\n",
    "            y_pred = np.argmax(neuron, axis=0)\n",
    "        return y_pred\n",
    "    \n",
    "    def set_init_dev_prefix(self):\n",
    "        if self.cost_function == 'quadratic':\n",
    "            return -2 * (Y - self.neurons[-1])\n",
    "        if self.cost_function == 'cross_entropy':\n",
    "            return -2 * (Y - self.neurons[-1])\n",
    "            #to be continued\n",
    "\n",
    "    def _update_params(self,Y):\n",
    "        #double check\n",
    "        cur_dev_prefix = self.set_init_dev_prefix()\n",
    "        print(cur_dev_prefix.shape)\n",
    "        grads = []\n",
    "        for N,V,act,W in zip(self.neurons[1:],self.vects,self.activations,self.matrice)[::-1]:\n",
    "            #cur_dev_prefix *= self.activate_dev(V,N,act)\n",
    "            print(self.activate_dev(V,N,act).shape)\n",
    "            print(N.shape)\n",
    "            #grads.append(cur_dev_prefix @ N)\n",
    "            print(W.shape)\n",
    "            #cur_dev_prefix *= W\n",
    "        grads.reverse()\n",
    "        for W,grad in zip(self.matrice,grad):\n",
    "            W -= self.eta * grad\n",
    "        return\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        self.dims[0][0] = X.shape[1]\n",
    "        if len(np.unique(Y)) != self.dims[-1][-1]:\n",
    "            print('Error: output dimension is wrong!')\n",
    "            return False\n",
    "        self._initialize_params(X)\n",
    "        for i in range(self.epochs):\n",
    "            #self.eta = self.learning_rate(self.eta,i,self.epochs)\n",
    "            #for adaptive learning rate\n",
    "            self._feedforward()\n",
    "            self._update_params(Y)\n",
    "            if verbose and not i % (self.epochs//100):\n",
    "                if self.metric == 'accuracy':\n",
    "                    accu = accuracy_score(self.neurons[-1],y)\n",
    "                print('{} percent finished, current accuracy is {}.'.format(100*i//self.epochs,accu))\n",
    "        print('Training is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (20,16) and (151,15) not aligned: 16 (dim 1) != 151 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b30ad38accdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Activation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftMax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;31m#model.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-a1e8ef1102e3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m#self.eta = self.learning_rate(self.eta,i,self.epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m#for adaptive learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-a1e8ef1102e3>\u001b[0m in \u001b[0;36m_feedforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_bias_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (20,16) and (151,15) not aligned: 16 (dim 1) != 151 (dim 0)"
     ]
    }
   ],
   "source": [
    "class TANH:\n",
    "    def val(x):\n",
    "        return np.tanh(x)\n",
    "    def dev(x):\n",
    "        return 1 - np.tanh(x)^2\n",
    "class Sigmoid:\n",
    "    def val(x):\n",
    "        return np.tanh(x)\n",
    "    def dev(x):\n",
    "        return 1 - np.tanh(x)^2\n",
    "class Relu:\n",
    "    def val(x):\n",
    "        return np.tanh(x)\n",
    "    def dev(x):\n",
    "        return 1 - np.tanh(x)^2\n",
    "class SoftMax:\n",
    "    def val(x):\n",
    "        return np.tanh(x)\n",
    "    def dev(x):\n",
    "        return 1 - np.tanh(x)^2\n",
    "        \n",
    "model = Sequential(C=0.0, epochs=10, eta=0.001, random_state=None, \n",
    "                 cost_function='quadratic', \n",
    "                 metric='accuracy',\n",
    "                 verbose=1,\n",
    "                 regular='None')\n",
    "model.add('Dense',15)\n",
    "model.add('Activation',Sigmoid)\n",
    "model.add('Dropout',0.9)\n",
    "model.add('Dense',20)\n",
    "model.add('Activation',Relu)\n",
    "model.add('Dropout',0.8)\n",
    "model.add('Dense',30)\n",
    "model.add('Activation',TANH)\n",
    "model.add('Dropout',0.6)\n",
    "model.add('Dense',3)\n",
    "model.add('Activation',SoftMax)\n",
    "\n",
    "model.fit(X,Y)\n",
    "#model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
